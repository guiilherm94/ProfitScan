import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { GoogleGenAI } from '@google/genai'
import { createClient } from '@supabase/supabase-js'

const supabaseAdmin = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
)

// Initialize AI clients
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
const gemini = new GoogleGenAI({ apiKey: process.env.GOOGLE_GENAI_API_KEY || '' })

interface AIConfig {
    currentProvider: string
    fallbackEnabled: boolean
    fallbackProvider: string
}

const SYSTEM_PROMPT = `Voc√™ √© um consultor financeiro especialista em micro e pequenos neg√≥cios brasileiros, especialmente MEIs.

SUAS TAREFAS:
1. IDENTIFICAR O NICHO: Baseado no nome do produto, identifique o setor (alimenta√ß√£o, moda, artesanato, servi√ßos, etc.)
2. MARGEM IDEAL DO SETOR: Informe qual a margem de lucro saud√°vel para aquele nicho espec√≠fico (ex: alimenta√ß√£o 25-35%, moda 50-100%, artesanato 40-60%)
3. DIAGN√ìSTICO: Compare a margem do usu√°rio com a margem ideal do setor
4. A√á√ÉO CONCRETA: D√™ UMA a√ß√£o espec√≠fica e pr√°tica que ele pode fazer HOJE

FORMATO DA RESPOSTA (use emojis para visual):
üìä **Nicho:** [identificar setor]
üìà **Margem ideal do setor:** [X-Y%]
[Se preju√≠zo: üö® ALERTA / Se abaixo do ideal: ‚ö†Ô∏è ATEN√á√ÉO / Se bom: ‚úÖ SAUD√ÅVEL]
üí° **A√ß√£o:** [conselho espec√≠fico e acion√°vel]

REGRAS:
- Seja direto mas emp√°tico
- M√°ximo 4-5 linhas
- Se for preju√≠zo, seja firme mas construtivo
- Inclua n√∫meros espec√≠ficos quando poss√≠vel (ex: "aumente R$2 no pre√ßo" ou "margem deveria ser pelo menos 30%")
- Considere que o usu√°rio √© MEI com recursos limitados`

// Get AI configuration from database
async function getAIConfig(): Promise<AIConfig> {
    try {
        const { data } = await supabaseAdmin
            .from('system_settings')
            .select('value')
            .eq('key', 'ai_config')
            .single()

        return data?.value || {
            currentProvider: 'gemini-2.0-flash-lite',
            fallbackEnabled: true,
            fallbackProvider: 'gpt5-nano'
        }
    } catch {
        return {
            currentProvider: 'gemini-2.0-flash-lite',
            fallbackEnabled: true,
            fallbackProvider: 'gpt5-nano'
        }
    }
}

// Call OpenAI GPT-5 nano
async function callOpenAI(prompt: string): Promise<string> {
    console.log('ü§ñ [Analyze] Usando GPT-5 nano')

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const response = await (openai.responses as any).create({
        model: 'gpt-5-nano',
        input: [
            { type: 'message', role: 'developer', content: [{ type: 'input_text', text: SYSTEM_PROMPT }] },
            { type: 'message', role: 'user', content: [{ type: 'input_text', text: prompt }] }
        ],
        reasoning: { effort: 'minimal' },
        text: { verbosity: 'low' },
        max_output_tokens: 500
    })

    return response.output_text || ''
}

// Call Gemini model
async function callGeminiModel(prompt: string, modelId: string): Promise<string> {
    console.log(`ü§ñ [Analyze] Usando ${modelId}`)

    const response = await gemini.models.generateContent({
        model: modelId,
        contents: [{ text: `${SYSTEM_PROMPT}\n\n${prompt}` }]
    })

    return response.text || ''
}

// Map provider names to Gemini model IDs
const GEMINI_MODEL_IDS: Record<string, string> = {
    'gemini-2.0-flash': 'gemini-2.0-flash',
    'gemini-2.0-flash-lite': 'gemini-2.0-flash-lite',
    'gemini-2.5-flash-lite': 'gemini-2.5-flash-lite'
}

// Call the appropriate AI model
async function callAIModel(provider: string, prompt: string): Promise<string> {
    if (provider === 'gpt5-nano') {
        return await callOpenAI(prompt)
    } else if (GEMINI_MODEL_IDS[provider]) {
        return await callGeminiModel(prompt, GEMINI_MODEL_IDS[provider])
    } else {
        console.warn(`‚ö†Ô∏è Unknown provider: ${provider}, defaulting to gpt5-nano`)
        return await callOpenAI(prompt)
    }
}

// Process with fallback
async function processWithFallback(prompt: string, aiConfig: AIConfig): Promise<{ content: string; providerUsed: string }> {
    let providerUsed = aiConfig.currentProvider

    try {
        const content = await callAIModel(aiConfig.currentProvider, prompt)
        return { content, providerUsed }
    } catch (primaryError) {
        console.error('‚ùå [Analyze] Erro no provider principal:', primaryError)

        if (aiConfig.fallbackEnabled && aiConfig.fallbackProvider) {
            console.log(`üîÑ [Analyze] Tentando fallback: ${aiConfig.fallbackProvider}`)
            providerUsed = aiConfig.fallbackProvider

            try {
                const content = await callAIModel(aiConfig.fallbackProvider, prompt)
                return { content, providerUsed }
            } catch (fallbackError) {
                console.error('‚ùå [Analyze] Erro no fallback:', fallbackError)
                throw fallbackError
            }
        } else {
            throw primaryError
        }
    }
}

export async function POST(request: NextRequest) {
    try {
        const body = await request.json()
        const { produto, custoProducao, precoVenda, custosFixos, margem, lucro, isPrejuizo, status, statusMessage } = body

        // Validate input
        if (!produto || precoVenda <= 0) {
            return NextResponse.json({ error: 'Dados inv√°lidos' }, { status: 400 })
        }

        // Get AI configuration
        const aiConfig = await getAIConfig()
        console.log('üìä [Analyze] Provider:', aiConfig.currentProvider)

        // Prepare user message for AI with more context
        const margemIdealSugestao = margem < 0 ? 'PREJU√çZO GRAVE' : margem < 15 ? 'MUITO BAIXA' : margem < 25 ? 'ABAIXO DO IDEAL' : margem < 40 ? 'ACEIT√ÅVEL' : 'BOA'

        const userMessage = `
Produto: ${produto}
Custo de Produ√ß√£o: R$ ${custoProducao.toFixed(2)}
Pre√ßo de Venda: R$ ${precoVenda.toFixed(2)}
Custos Fixos/Impostos: ${custosFixos}%
Lucro L√≠quido por unidade: R$ ${lucro.toFixed(2)}
Margem de Lucro Atual: ${margem.toFixed(1)}%
Avalia√ß√£o do Sistema: ${status?.toUpperCase() || margemIdealSugestao} - ${statusMessage || 'Sem mensagem'}
Situa√ß√£o: ${isPrejuizo ? 'PREJU√çZO - URGENTE!' : margem < 15 ? 'MARGEM BAIXA - ATEN√á√ÉO' : 'OPERANDO COM LUCRO'}

Analise este produto e me d√™ sua consultoria especializada.`

        // Process with AI
        const result = await processWithFallback(userMessage, aiConfig)
        console.log('‚úÖ [Analyze] Processado com:', result.providerUsed)

        // Save to history if possible
        try {
            const supabase = createClient(
                process.env.NEXT_PUBLIC_SUPABASE_URL!,
                process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
            )
            const { data: { session } } = await supabase.auth.getSession()

            if (session) {
                const userId = session.user.id

                await supabase.from('history').insert({
                    user_id: userId,
                    produto,
                    custo_producao: custoProducao,
                    preco_venda: precoVenda,
                    custos_fixos: custosFixos,
                    margem,
                    resposta_ia: result.content
                })

                // Limit to 100 entries per user
                const { count } = await supabase
                    .from('history')
                    .select('*', { count: 'exact', head: true })
                    .eq('user_id', userId)

                if (count && count > 100) {
                    const entriesToDelete = count - 100
                    const { data: oldestEntries } = await supabase
                        .from('history')
                        .select('id')
                        .eq('user_id', userId)
                        .order('created_at', { ascending: true })
                        .limit(entriesToDelete)

                    if (oldestEntries && oldestEntries.length > 0) {
                        const idsToDelete = oldestEntries.map(e => e.id)
                        await supabase.from('history').delete().in('id', idsToDelete)
                    }
                }
            }
        } catch (historyError) {
            console.error('Failed to save history:', historyError)
        }

        return NextResponse.json({
            analysis: result.content,
            provider_used: result.providerUsed
        })

    } catch (error) {
        console.error('‚ùå [Analyze] Erro:', error)
        const errorMessage = error instanceof Error ? error.message : 'Erro ao processar an√°lise'
        return NextResponse.json({ error: errorMessage }, { status: 500 })
    }
}

export const dynamic = 'force-dynamic'
